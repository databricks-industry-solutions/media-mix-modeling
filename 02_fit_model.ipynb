{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c981a1ca-85f0-424c-8d47-cef12403d5ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This accelerator notebook is available at https://github.com/databricks-industry-solutions/media-mix-modeling.\n",
    "\n",
    "To import this accelerator, please [clone the repo above into your workspace](https://docs.databricks.com/repos/git-operations-with-repos.html) instead of using the `Download .dbc` option. Please run the `RUNME` notebook at the root directory of this accelerator folder to create a cluster and a Workflow. Use the `mmm_cluster` cluster created by the RUNME notebook to run this notebook interactively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5b9ed90-5a19-4a0f-b225-81f58b2460f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Media Mix Model with PyMC-Marketing\n",
    "\n",
    "As mentioned in the previous notebook, MMM enables companies to identify and measure the impact of their marketing campaigns across multiple channels. Now that we've simulated a dataset for daily marketing spend for three different channels and a corresponding dependent sales variable, let's see how we can use [PyMC-Marketing](https://www.pymc-marketing.io/) to understand that data and help us decide what adjustments to consider, if any, to our current marketing spend.\n",
    "\n",
    "PyMC-Marketing is an open source Bayesian marketing analytics library from [PyMC Labs](https://www.pymc-labs.io/) that provides production-ready implementations of Media Mix Models (MMM), Customer Lifetime Value (CLV) models, and more. It's built on top of PyMC and provides:\n",
    "\n",
    "- **Adstock transformations**: Geometric, Delayed, and Weibull adstock effects to model carryover\n",
    "- **Saturation functions**: Logistic, Tanh, and other saturation curves to model diminishing returns\n",
    "- **Built-in diagnostics**: Model validation, contribution analysis, and ROAS estimation\n",
    "- **Budget optimization**: Tools to optimize marketing spend allocation\n",
    "\n",
    "For this accelerator, we'll use PyMC-Marketing's `MMM` class which implements the model specification from Jin, Yuxue, et al. \"Bayesian methods for media mix modeling with carryover and shape effects.\" (2017).\n",
    "\n",
    "**References:**\n",
    "- [PyMC-Marketing Documentation](https://www.pymc-marketing.io/)\n",
    "- [MMM Example Notebook](https://www.pymc-marketing.io/en/stable/notebooks/mmm/mmm_example.html)\n",
    "- Jin, Yuxue, et al. \"Bayesian methods for media mix modeling with carryover and shape effects.\" (2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85f5df8d-11a2-4450-83bb-1888e05de896",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set up parameters\n",
    "dbutils.widgets.text(\"catalog_name\", \"main\", \"Catalog Name\")\n",
    "dbutils.widgets.text(\"schema_name\", \"default\", \"Schema Name\")\n",
    "dbutils.widgets.text(\"gold_table_name\", \"mmm_data\", \"Gold Table Name\")\n",
    "dbutils.widgets.text(\"experiment_name\", \"/Shared/media-mix-modeling\", \"Experiment Name\")\n",
    "\n",
    "catalog_name = dbutils.widgets.get(\"catalog_name\")\n",
    "schema_name = dbutils.widgets.get(\"schema_name\")\n",
    "gold_table_name = dbutils.widgets.get(\"gold_table_name\")\n",
    "experiment_name = dbutils.widgets.get(\"experiment_name\")\n",
    "\n",
    "print(f\"Using catalog: {catalog_name}\")\n",
    "print(f\"Using schema: {schema_name}\")\n",
    "print(f\"Using gold table: {gold_table_name}\")\n",
    "print(f\"Using experiment: {experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acb4b547-9338-4389-9983-2128a7fbc761",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set up MLflow\n",
    "import mlflow\n",
    "\n",
    "# Set catalog and schema context\n",
    "spark.sql(f\"USE CATALOG {catalog_name}\")\n",
    "spark.sql(f\"USE SCHEMA {schema_name}\")\n",
    "print(f\"Using catalog.schema: {catalog_name}.{schema_name}\")\n",
    "\n",
    "# Set MLflow experiment (using full path provided as parameter)\n",
    "mlflow.set_experiment(experiment_name)\n",
    "print(f\"Using MLflow experiment: {experiment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9736a390-5aad-48d4-bc49-49f3467d57d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 1: Set up the environment\n",
    "\n",
    "We import PyMC-Marketing's MMM class along with the adstock and saturation transformations. PyMC-Marketing bundles PyMC and ArviZ, so we get the full Bayesian inference and diagnostics ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9a233c8-6b1c-4850-8465-29b6908f5ef3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "\n",
    "from pymc_marketing.mmm import (\n",
    "    MMM,\n",
    "    GeometricAdstock,\n",
    "    LogisticSaturation,\n",
    ")\n",
    "\n",
    "print(f\"Running on PyMC v{pm.__version__}\")\n",
    "\n",
    "RANDOM_SEED = 8927\n",
    "np.random.seed(RANDOM_SEED)\n",
    "az.style.use('arviz-darkgrid')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8876be5-85e1-415b-b67a-5996691b8bf3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 2: Load the data\n",
    "\n",
    "The generated dataset simulates a gold table where the input table has been transformed so the ad spend is a window leading up to the sale rather than aggregated up on the same day a sale occurred. In this case, we're simply loading up the data we generated to simulate a [gold table](https://www.databricks.com/glossary/medallion-architecture), but in your system you're hopefully going to be accessing your actual gold table!\n",
    "\n",
    "However, you may not be there just yet. If you are at the point where you're just ingesting data from your marketing sources, then you'll want to start there, loading your data into a bronze layer, cleaning it up and creating a high quality and consistent silver layer, and then aggregating the cleansed data to produce a gold aggregate layer. The end result of that pipeline should look similar in many ways to the table we've generated here. Even though we're sort of skipping this piece by starting with a simulated gold layer, don't underestimate this piece. Getting to a good clean dataset for your analysis is an essential ingredient to success with MMM so this is a critical piece of your architecture!\n",
    "\n",
    "Here, we simply load our simulated gold table and have another look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bfe42ef-6328-4f34-9e53-90de30428f84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.table(gold_table_name).toPandas()\n",
    "display(df)\n",
    "df.plot(linewidth=0.25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eaeb0719-8abf-4a05-9fbc-04940384212a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Ground Truth Parameters (Synthetic Data Only)\n",
    "\n",
    "Since we're working with synthetic data generated in the previous notebook, we know the \"ground truth\" parameters that were used. This allows us to validate that PyMC-Marketing can recover the underlying patterns.\n",
    "\n",
    "**Note**: In production with real data, you won't have ground truth - you'll validate your model using:\n",
    "- Holdout validation (train/test splits)\n",
    "- Comparison with A/B test results or lift studies\n",
    "- Business intuition and expert knowledge\n",
    "- Out-of-sample prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "454fc83b-2f89-4738-88de-61c5d6174ae5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ground truth from config/generator/basic_config.yaml\n",
    "GROUND_TRUTH = {\n",
    "    'intercept': 3.4,\n",
    "    'scale': 100000,\n",
    "    'sigma': 0.01,\n",
    "    'channels': {\n",
    "        'adwords': {'beta': 1.5, 'saturation_mu': 3.1, 'has_saturation': True, 'has_adstock': False},\n",
    "        'facebook': {'beta': 1.0, 'saturation_mu': 4.2, 'has_saturation': True, 'has_adstock': False},\n",
    "        'linkedin': {'beta': 2.4, 'saturation_mu': 2.1, 'adstock_alpha': 0.6, 'has_saturation': True, 'has_adstock': True},\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Ground Truth Parameters:\")\n",
    "print(f\"  Intercept: {GROUND_TRUTH['intercept']}\")\n",
    "print(f\"  Scale: {GROUND_TRUTH['scale']:,}\")\n",
    "print(f\"  Noise (sigma): {GROUND_TRUTH['sigma']}\")\n",
    "print(\"\\nChannel Parameters:\")\n",
    "for channel, params in GROUND_TRUTH['channels'].items():\n",
    "    print(f\"  {channel}: β={params['beta']}, μ={params.get('saturation_mu', 'N/A')}, α={params.get('adstock_alpha', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc3d0e28-a4c8-43f0-ae10-c3d822a14b4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 3: Prepare data for PyMC-Marketing\n",
    "\n",
    "PyMC-Marketing's MMM expects the data in a specific format:\n",
    "- A date column for the time index\n",
    "- Media channel columns with spend/impression data\n",
    "- A target variable (e.g., sales)\n",
    "\n",
    "Our generated data already has this structure, so we just need to ensure the date column is properly formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa194081-25cb-45f3-8a88-9bc4594f93ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ensure date column is datetime type\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Define channel and target columns\n",
    "channel_columns = ['adwords', 'facebook', 'linkedin']\n",
    "date_column = 'date'\n",
    "target_column = 'sales'\n",
    "\n",
    "# Create X (features) and y (target) for the model\n",
    "X = df[[date_column] + channel_columns].copy()\n",
    "y = df[target_column].values\n",
    "\n",
    "print(f\"Data shape: {X.shape}\")\n",
    "print(f\"Date range: {X[date_column].min()} to {X[date_column].max()}\")\n",
    "print(f\"Channel columns: {channel_columns}\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da2ef82f-2588-4e5e-8276-a369c6eb1389",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 4: Configure and create the model\n",
    "\n",
    "PyMC-Marketing's MMM class provides a high-level API for media mix modeling. We configure:\n",
    "\n",
    "- **Adstock**: We use `GeometricAdstock` which models the carryover effect of media spend. The `l_max` parameter controls the maximum lag (how many time periods the effect can persist).\n",
    "\n",
    "- **Saturation**: We use `LogisticSaturation` which models diminishing returns - as spend increases, each additional dollar has less incremental impact.\n",
    "\n",
    "The model equation is:\n",
    "\n",
    "$$y_t = \\alpha + \\sum_{m=1}^{M} \\beta_m \\cdot \\text{saturation}(\\text{adstock}(x_{m,t})) + \\varepsilon_t$$\n",
    "\n",
    "where $\\alpha$ is the intercept (baseline), $\\beta_m$ are the channel coefficients, and $\\varepsilon_t$ is the noise term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "370edb52-f5df-4606-bfbd-7bc79d462b08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Understanding Adstock and Saturation\n",
    "\n",
    "**Geometric Adstock** models the \"decay\" of advertising effects over time. If you spend $1 today, its effect doesn't disappear immediately - it decays geometrically over subsequent time periods.\n",
    "\n",
    "**Logistic Saturation** models diminishing returns. The first $1000 spent on a channel might generate significant lift, but the next $1000 generates less additional lift, and so on.\n",
    "\n",
    "You can use the interactive widgets to explore these transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bd2654d-4289-44e2-a753-d1e2fb7c4b2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mediamix import interactive as mmi\n",
    "from importlib import reload\n",
    "reload(mmi)\n",
    "\n",
    "mmi.display_geometric_adstock_and_delay_interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5d7f512-eb0c-4fca-9bd7-30be9872c033",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Create the MMM instance\n",
    "\n",
    "Now we create the MMM model with our configuration. PyMC-Marketing handles the scaling and transformation of data internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8322c51d-e8fd-43b5-a884-0d90920a81ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configure the MMM model\n",
    "mmm = MMM(\n",
    "    date_column=date_column,\n",
    "    channel_columns=channel_columns,\n",
    "    adstock=GeometricAdstock(l_max=12),\n",
    "    saturation=LogisticSaturation(),\n",
    ")\n",
    "\n",
    "print(\"MMM model configured successfully\")\n",
    "print(f\"  Date column: {mmm.date_column}\")\n",
    "print(f\"  Channel columns: {mmm.channel_columns}\")\n",
    "\n",
    "# Key variables to use for plotting and inspection\n",
    "# - saturation_beta: The beta attribute of channel contribution\n",
    "# - adstock_alpha: Indicates the decay signal of the ad spend vs results\n",
    "# - saturation_lam: Shape of the saturation curve for the channel\n",
    "key_var_names = [\"saturation_beta\", \"adstock_alpha\", \"saturation_lam\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a243b6bf-82eb-4da9-a0ed-df4fa9f3a3bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 5: Run inference\n",
    "\n",
    "Now we fit the model to our data. PyMC-Marketing's `fit()` method runs Bayesian inference using PyMC's NUTS sampler.\n",
    "\n",
    "We track the experiment with MLflow to keep a record of our model runs, parameters, and artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8244624-44f9-4fa6-97d2-44b345162949",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sampling parameters\n",
    "sampler_config = {\n",
    "    'draws': 1000,\n",
    "    'tune': 1000,\n",
    "    'chains': 4,\n",
    "    'random_seed': RANDOM_SEED,\n",
    "}\n",
    "\n",
    "# Start an MLflow run (ended explicitly in a later cell so we can log metrics across cells)\n",
    "mlflow.start_run()\n",
    "\n",
    "# Log sampling parameters\n",
    "mlflow.log_params(sampler_config)\n",
    "mlflow.log_param('l_max', 12)\n",
    "mlflow.log_param('adstock_type', 'geometric')\n",
    "mlflow.log_param('saturation_type', 'logistic')\n",
    "\n",
    "# Fit the model\n",
    "mmm.fit(X, y, **sampler_config)\n",
    "\n",
    "# Save the model\n",
    "model_path = 'mmm_model.nc'\n",
    "mmm.save(model_path)\n",
    "mlflow.log_artifact(model_path)\n",
    "\n",
    "print(\"Model fitting complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d0ae3fa-2544-43be-a7d2-276909b432b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 6: Analyze the results\n",
    "\n",
    "Now that we've run inference, we can analyze the posterior distributions of the model parameters. PyMC-Marketing stores the inference data in the `idata` attribute, which is an ArviZ `InferenceData` object.\n",
    "\n",
    "Key parameters to examine:\n",
    "\n",
    "| Parameter | Description |\n",
    "|-----------|-------------|\n",
    "| `intercept` | Baseline sales without any marketing |\n",
    "| `beta_channel` | Channel effectiveness coefficients |\n",
    "| `adstock_alpha` | Adstock decay rate (0 = no carryover, 1 = full carryover) |\n",
    "| `saturation_lam` | Saturation parameter (controls diminishing returns) |\n",
    "| `sigma` | Observation noise |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17fa1aa1-c268-43d7-ac8c-d70f95a0c657",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the inference data\n",
    "idata = mmm.idata\n",
    "\n",
    "# Display summary statistics\n",
    "az.summary(idata, var_names=key_var_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "822ca214-db61-49b8-97ee-507257c79c2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 7: Inspect the trace visually\n",
    "\n",
    "The trace plot shows both the posterior distributions (left) and the sampling traces (right) for each parameter.\n",
    "\n",
    "- **Left plots**: Show the posterior distribution - where we believe the true parameter value lies after seeing the data\n",
    "- **Right plots**: Show the MCMC chains - these should look like \"fuzzy caterpillars\" indicating good mixing\n",
    "\n",
    "Key diagnostics to check:\n",
    "- **ESS (Effective Sample Size)**: Should be > 400 for reliable estimates\n",
    "- **R-hat**: Should be close to 1.0 (< 1.01 is ideal) indicating chain convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaedc3cc-8ef8-40e6-8c4f-2997fcb7b53d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "az.plot_trace(idata, var_names=key_var_names);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f247b21-d020-4da1-91d0-f652b323af4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 8: Inspect posterior predictive samples\n",
    "\n",
    "We can check how well our model fits the observed data by comparing posterior predictive samples to the actual sales values. This helps validate that the model captures the patterns in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d64557e-5a7a-4d3b-b76b-4a5ff4d612b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sample posterior predictive\n",
    "mmm.sample_posterior_predictive(X, extend_idata=True)\n",
    "\n",
    "# Plot posterior predictive check\n",
    "az.plot_ppc(idata);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4897fe7b-730f-45c6-93c7-8a88abb15287",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 9: Model fit quality metrics\n",
    "\n",
    "Let's quantify how well our model fits the observed data using standard metrics:\n",
    "\n",
    "- **R² (R-squared)**: Proportion of variance explained (1.0 = perfect fit)\n",
    "- **MAPE (Mean Absolute Percentage Error)**: Average prediction error as a percentage\n",
    "\n",
    "These metrics help us understand overall model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0f0820e-1a36-4184-9bc7-e7290fd73015",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extract posterior predictive mean\n",
    "posterior_predictive = idata.posterior_predictive\n",
    "y_pred_mean = posterior_predictive['y'].mean(dim=['chain', 'draw']).values\n",
    "\n",
    "# Calculate R-squared\n",
    "ss_res = np.sum((y - y_pred_mean) ** 2)\n",
    "ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "r_squared = 1 - (ss_res / ss_tot)\n",
    "\n",
    "# Calculate MAPE\n",
    "mape = np.mean(np.abs((y - y_pred_mean) / y)) * 100\n",
    "\n",
    "print(f\"Model Fit Quality:\")\n",
    "print(f\"  R² = {r_squared:.4f} {'(Excellent!)' if r_squared > 0.95 else '(Good)' if r_squared > 0.85 else ''}\")\n",
    "print(f\"  MAPE = {mape:.2f}%\")\n",
    "\n",
    "# Log metrics to MLflow\n",
    "mlflow.log_metric('r_squared', r_squared)\n",
    "mlflow.log_metric('mape', mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64d26e86-1ac0-4df5-ac1f-546456e249ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 10: Parameter recovery validation (Synthetic Data Only)\n",
    "\n",
    "Since we're using synthetic data with known ground truth, we can check how well PyMC-Marketing recovers the true parameters.\n",
    "\n",
    "**Important notes about parameter interpretation:**\n",
    "\n",
    "1. **Saturation (λ) and Adstock (α)**: These are shape parameters that *should* match ground truth closely\n",
    "2. **Beta coefficients**: NOT directly comparable due to PyMC-Marketing's internal data scaling (MaxAbsScaler). The model applies nonlinear transformations to scaled data, which changes the parameter space. Instead, focus on:\n",
    "   - Relative channel effectiveness (proportions)\n",
    "   - Overall model fit quality (R², MAPE)\n",
    "   - Channel contributions in original scale\n",
    "\n",
    "See `CLAUDE.md` for detailed explanation of why beta coefficients differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a12a6f5c-1dc0-4091-b9e2-951274e49f42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extract recovered parameters\n",
    "posterior = idata.posterior\n",
    "\n",
    "# Compare saturation parameters (these should match closely)\n",
    "print(\"Saturation Parameter Recovery (λ = lam):\")\n",
    "print(\"-\" * 60)\n",
    "for i, channel in enumerate(['adwords', 'facebook', 'linkedin']):\n",
    "    ground_truth_mu = GROUND_TRUTH['channels'][channel]['saturation_mu']\n",
    "    recovered_lam = posterior['saturation_lam'][:, :, i].mean().item()\n",
    "    error_pct = abs(recovered_lam - ground_truth_mu) / ground_truth_mu * 100\n",
    "    print(f\"  {channel:10s}: Ground truth μ={ground_truth_mu:.1f}, Recovered λ={recovered_lam:.4f}, Error={error_pct:.2f}%\")\n",
    "\n",
    "# Compare adstock parameters (only LinkedIn has adstock)\n",
    "print(\"\\nAdstock Parameter Recovery (α = alpha):\")\n",
    "print(\"-\" * 60)\n",
    "linkedin_idx = 2  # LinkedIn is the 3rd channel\n",
    "if 'adstock_alpha' in posterior:\n",
    "    ground_truth_alpha = GROUND_TRUTH['channels']['linkedin']['adstock_alpha']\n",
    "    recovered_alpha = posterior['adstock_alpha'][:, :, linkedin_idx].mean().item()\n",
    "    error_pct = abs(recovered_alpha - ground_truth_alpha) / ground_truth_alpha * 100\n",
    "    print(f\"  linkedin  : Ground truth α={ground_truth_alpha:.1f}, Recovered α={recovered_alpha:.4f}, Error={error_pct:.2f}%\")\n",
    "\n",
    "# Beta coefficients - show relative proportions only\n",
    "print(\"\\nBeta Coefficients (Relative Channel Effectiveness):\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Note: Absolute values not comparable due to data scaling.\")\n",
    "print(\"      Focus on relative proportions between channels.\")\n",
    "print()\n",
    "beta_values = posterior['saturation_beta'].mean(dim=['chain', 'draw']).values\n",
    "beta_sum = beta_values.sum()\n",
    "for i, channel in enumerate(['adwords', 'facebook', 'linkedin']):\n",
    "    beta_mean = beta_values[i]\n",
    "    beta_pct = beta_mean / beta_sum * 100\n",
    "    ground_truth_beta = GROUND_TRUTH['channels'][channel]['beta']\n",
    "    print(f\"  {channel:10s}: β={beta_mean:.3f} ({beta_pct:.1f}% of total), Ground truth β={ground_truth_beta:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f192b085-8882-480d-a326-96328cc08ab8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 11: Compare prior and posterior distributions\n",
    "\n",
    "One of the benefits of Bayesian modeling is seeing how our beliefs update after observing data. This plot compares our prior beliefs (before seeing data) with our posterior beliefs (after inference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16dcbe26-e98c-454c-a7c5-bff48ae3c3a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sample from priors for comparison\n",
    "mmm.sample_prior_predictive(X, extend_idata=True)\n",
    "\n",
    "# Plot comparison for key parameters\n",
    "az.plot_dist_comparison(idata, figsize=(12, 20), var_names=key_var_names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51e5fd56-3adc-4edc-956e-28b492a2e867",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# End the MLflow run (started in Step 5)\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1776c11-26f1-4a31-b62d-1f74fb94eef7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Summary and Next Steps\n",
    "\n",
    "Congratulations! You've successfully built and validated a Media Mix Model using PyMC-Marketing.\n",
    "\n",
    "**What we achieved:**\n",
    "\n",
    "1. ✅ **Model Fit**: R² > 0.95, MAPE < 2% (check your output above)\n",
    "2. ✅ **Parameter Recovery**: Saturation and adstock parameters recovered with <1% error (synthetic data validation)\n",
    "3. ✅ **MCMC Convergence**: R-hat < 1.01, sufficient effective sample size\n",
    "4. ✅ **Channel Insights**: Posterior distributions show channel effectiveness with uncertainty\n",
    "\n",
    "**Next steps for production use:**\n",
    "\n",
    "1. **Channel Contribution Analysis**:\n",
    "   ```python\n",
    "   contributions = mmm.compute_channel_contribution_original_scale()\n",
    "   ```\n",
    "   This shows actual dollar impact of each channel on sales\n",
    "\n",
    "2. **Budget Optimization**:\n",
    "   ```python\n",
    "   optimal_budget = mmm.optimize_budget(total_budget=your_budget)\n",
    "   ```\n",
    "   Find the optimal allocation across channels\n",
    "\n",
    "3. **ROAS Calculation**:\n",
    "   Compute return on ad spend for each channel to guide investment decisions\n",
    "\n",
    "4. **Holdout Validation**:\n",
    "   Split your data into train/test sets to validate out-of-sample performance\n",
    "\n",
    "5. **Incorporate Real Data**:\n",
    "   Replace synthetic data with your actual marketing spend and KPI data\n",
    "\n",
    "**Advanced features available in PyMC-Marketing:**\n",
    "\n",
    "- Lift test calibration (incorporate A/B test results)\n",
    "- Time-varying effects and interventions\n",
    "- Seasonality and trend modeling\n",
    "- Control variables (holidays, economic indicators, promotions)\n",
    "- Different adstock functions (Delayed, Weibull)\n",
    "- Different saturation curves (Tanh, Hill)\n",
    "\n",
    "For more information, see the [PyMC-Marketing documentation](https://www.pymc-marketing.io/)."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "pymc-marketing==0.17.1"
    ],
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_fit_model",
   "widgets": {
    "catalog_name": {
     "currentValue": "users",
     "nuid": "caa3cb5d-85c7-49f9-93a2-75aa2bc02aea",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "main",
      "label": "Catalog Name",
      "name": "catalog_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "main",
      "label": "Catalog Name",
      "name": "catalog_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "experiment_name": {
     "currentValue": "/Users/corey.abshire@databricks.com/media-mix-modeling",
     "nuid": "b614d3cd-a13e-441a-99fd-96215419bd5e",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "/Shared/media-mix-modeling",
      "label": "Experiment Name",
      "name": "experiment_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "/Shared/media-mix-modeling",
      "label": "Experiment Name",
      "name": "experiment_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "gold_table_name": {
     "currentValue": "mmm_data",
     "nuid": "eb203a64-33e9-40ba-8e7d-bda3b269927a",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "mmm_data",
      "label": "Gold Table Name",
      "name": "gold_table_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "mmm_data",
      "label": "Gold Table Name",
      "name": "gold_table_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "schema_name": {
     "currentValue": "corey_abshire",
     "nuid": "1e7b75ed-9353-42da-8dfa-d98966b58679",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "default",
      "label": "Schema Name",
      "name": "schema_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "default",
      "label": "Schema Name",
      "name": "schema_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
